{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad91d67-1751-4229-a733-11de125dc1ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T06:11:05.328351Z",
     "iopub.status.busy": "2025-10-07T06:11:05.328118Z",
     "iopub.status.idle": "2025-10-07T06:11:10.055285Z",
     "shell.execute_reply": "2025-10-07T06:11:10.054582Z",
     "shell.execute_reply.started": "2025-10-07T06:11:05.328326Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-crf\n",
      "  Downloading pytorch_crf-0.7.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
      "Installing collected packages: pytorch-crf\n",
      "Successfully installed pytorch-crf-0.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "502b85e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T06:11:38.531454Z",
     "iopub.status.busy": "2025-10-07T06:11:38.530788Z",
     "iopub.status.idle": "2025-10-07T06:11:38.535054Z",
     "shell.execute_reply": "2025-10-07T06:11:38.534331Z",
     "shell.execute_reply.started": "2025-10-07T06:11:38.531428Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch import nn\n",
    "from torchcrf import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3112168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T06:11:43.025613Z",
     "iopub.status.busy": "2025-10-07T06:11:43.024678Z",
     "iopub.status.idle": "2025-10-07T06:11:43.039160Z",
     "shell.execute_reply": "2025-10-07T06:11:43.038340Z",
     "shell.execute_reply.started": "2025-10-07T06:11:43.025573Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_conll_for_bilstm(file_path, max_len=None, lowercase=True):\n",
    "    \"\"\"\n",
    "    Converts CoNLL data into indexed tensors for BiLSTM NER.\n",
    "    \n",
    "    Args:\n",
    "        file_path: path to .conll or .txt file\n",
    "        max_len: optional max sequence length for padding\n",
    "        lowercase: whether to convert tokens to lowercase\n",
    "    \n",
    "    Returns:\n",
    "        sentences_padded: Tensor (num_sentences, max_len)\n",
    "        tags_padded: Tensor (num_sentences, max_len)\n",
    "        token2idx, label2idx: dictionaries for mapping\n",
    "    \"\"\"\n",
    "    sentences, labels = [], []\n",
    "    sent, tag_seq = [], []\n",
    "\n",
    "    # Read and parse CoNLL file\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:  # end of sentence\n",
    "                if sent:\n",
    "                    sentences.append(sent)\n",
    "                    labels.append(tag_seq)\n",
    "                    sent, tag_seq = [], []\n",
    "            else:\n",
    "                parts = line.split()\n",
    "                token = parts[0]   # first column = value\n",
    "                if lowercase:\n",
    "                    token = token.lower()  # convert to lowercase\n",
    "                label = parts[-1]  # last column = label\n",
    "                sent.append(token)\n",
    "                tag_seq.append(label)\n",
    "        # Add last sentence if not empty\n",
    "        if sent:\n",
    "            sentences.append(sent)\n",
    "            labels.append(tag_seq)\n",
    "\n",
    "    # Build vocabularies\n",
    "    all_tokens = {t for s in sentences for t in s}\n",
    "    all_labels = {l for lab in labels for l in lab}\n",
    "\n",
    "    token2idx = {t: i + 2 for i, t in enumerate(sorted(all_tokens))}\n",
    "    token2idx[\"<PAD>\"] = 0\n",
    "    token2idx[\"<UNK>\"] = 1\n",
    "\n",
    "    label2idx = {l: i for i, l in enumerate(sorted(all_labels))}\n",
    "    pad_label_id = len(label2idx)\n",
    "    label2idx[\"<PAD>\"] = pad_label_id\n",
    "\n",
    "    # Convert to index sequences\n",
    "    X = [[token2idx.get(t, 1) for t in s] for s in sentences]\n",
    "    y = [[label2idx[l] for l in lab] for lab in labels]\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_tensors = [torch.tensor(seq, dtype=torch.long) for seq in X]\n",
    "    y_tensors = [torch.tensor(seq, dtype=torch.long) for seq in y]\n",
    "\n",
    "    # Pad sequences\n",
    "    if max_len is None:\n",
    "        max_len = max(len(seq) for seq in X_tensors)\n",
    "\n",
    "    sentences_padded = pad_sequence(\n",
    "        X_tensors, batch_first=True, padding_value=token2idx[\"<PAD>\"]\n",
    "    )\n",
    "    tags_padded = pad_sequence(\n",
    "        y_tensors, batch_first=True, padding_value=label2idx[\"<PAD>\"]\n",
    "    )\n",
    "\n",
    "    # Truncate if specified\n",
    "    sentences_padded = sentences_padded[:, :max_len]\n",
    "    tags_padded = tags_padded[:, :max_len]\n",
    "\n",
    "    return sentences_padded, tags_padded, token2idx, label2idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548253d-7927-43b6-bcb1-2bec47c9d394",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T14:37:47.255039Z",
     "iopub.status.busy": "2025-10-06T14:37:47.254770Z",
     "iopub.status.idle": "2025-10-06T14:37:47.272666Z",
     "shell.execute_reply": "2025-10-06T14:37:47.272029Z",
     "shell.execute_reply.started": "2025-10-06T14:37:47.255020Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset: torch.Size([137, 30]) torch.Size([137, 30])\n",
      "Train split : torch.Size([109, 30]) torch.Size([109, 30])\n",
      "Val split   : torch.Size([28, 30]) torch.Size([28, 30])\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_path = \"/kaggle/input/annotation/train.condll\"\n",
    "\n",
    "# train_X, train_y, token2idx, label2idx = load_conll_for_bilstm(train_path)\n",
    "\n",
    "# print(\"Full dataset:\", train_X.shape, train_y.shape)\n",
    "\n",
    "# train_X, val_X, train_y, val_y = train_test_split(\n",
    "#     train_X, train_y, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# print(\"Train split :\", train_X.shape, train_y.shape)\n",
    "# print(\"Val split   :\", val_X.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "488635fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T06:12:50.794930Z",
     "iopub.status.busy": "2025-10-07T06:12:50.794678Z",
     "iopub.status.idle": "2025-10-07T06:12:50.891969Z",
     "shell.execute_reply": "2025-10-07T06:12:50.891228Z",
     "shell.execute_reply.started": "2025-10-07T06:12:50.794912Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([346, 31])\n",
      "torch.Size([346, 31])\n"
     ]
    }
   ],
   "source": [
    "train_path = \"/kaggle/input/annotate/train.conll\"\n",
    "test_path = \"/kaggle/input/annotate/test.conll\"\n",
    "\n",
    "train_X, train_y, token2idx, label2idx = load_conll_for_bilstm(train_path)\n",
    "test_X, test_y, _, _ = load_conll_for_bilstm(test_path)\n",
    "\n",
    "print(train_X.shape) \n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b629d58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T06:12:54.479470Z",
     "iopub.status.busy": "2025-10-07T06:12:54.478831Z",
     "iopub.status.idle": "2025-10-07T06:12:54.488966Z",
     "shell.execute_reply": "2025-10-07T06:12:54.488282Z",
     "shell.execute_reply.started": "2025-10-07T06:12:54.479446Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchcrf import CRF\n",
    "\n",
    "class MaskedAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, lstm_out, mask):\n",
    "        # lstm_out: (batch, seq_len, hidden_dim)\n",
    "        scores = self.attn(lstm_out).squeeze(-1)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_weights = torch.softmax(scores, dim=1).unsqueeze(-1)\n",
    "        context = torch.sum(lstm_out * attn_weights, dim=1, keepdim=True)\n",
    "        return lstm_out + context.expand_as(lstm_out)\n",
    "\n",
    "\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, embedding_dim=128, hidden_dim=256, num_layers=2, dropout=0.25, pad_idx=0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.bilstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_dim // 2,\n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.attention = MaskedAttention(hidden_dim)\n",
    "\n",
    "        # optional hidden projection before CRF\n",
    "        self.hidden_fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.crf = CRF(tagset_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x, tags=None, mask=None):\n",
    "        if mask is None:\n",
    "            mask = (x != self.embedding.padding_idx).type(torch.bool)\n",
    "        mask[:, 0] = 1\n",
    "\n",
    "        embeddings = self.embedding(x)\n",
    "        embeddings = self.embedding_dropout(embeddings)\n",
    "\n",
    "        lstm_out, _ = self.bilstm(embeddings)\n",
    "        lstm_out = self.layer_norm(lstm_out)\n",
    "        lstm_out = self.attention(lstm_out, mask)\n",
    "        lstm_out = self.hidden_fc(lstm_out)\n",
    "\n",
    "        emissions = self.fc(lstm_out)\n",
    "\n",
    "        if tags is not None:\n",
    "            log_likelihood = self.crf(emissions, tags, mask=mask)\n",
    "            return -log_likelihood.mean()\n",
    "        else:\n",
    "            return self.crf.decode(emissions, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e30d4527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T06:12:57.872593Z",
     "iopub.status.busy": "2025-10-07T06:12:57.871905Z",
     "iopub.status.idle": "2025-10-07T06:12:58.284123Z",
     "shell.execute_reply": "2025-10-07T06:12:58.283573Z",
     "shell.execute_reply.started": "2025-10-07T06:12:57.872567Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "X = train_X.to(device)\n",
    "y = train_y.to(device)\n",
    "\n",
    "# Use boolean mask\n",
    "mask = (X != token2idx[\"<PAD>\"]).to(device).bool()\n",
    "\n",
    "model = BiLSTM_CRF(\n",
    "    vocab_size=len(token2idx),\n",
    "    tagset_size=len(label2idx),\n",
    "    embedding_dim=128,\n",
    "    hidden_dim=256,\n",
    "    pad_idx=token2idx[\"<PAD>\"]\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2a79cad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T06:13:01.373445Z",
     "iopub.status.busy": "2025-10-07T06:13:01.372842Z",
     "iopub.status.idle": "2025-10-07T06:13:08.128399Z",
     "shell.execute_reply": "2025-10-07T06:13:08.127772Z",
     "shell.execute_reply.started": "2025-10-07T06:13:01.373421Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 15378.2373\n",
      "Epoch 2/50, Loss: 21755.3750\n",
      "Epoch 3/50, Loss: 15868.3740\n",
      "Epoch 4/50, Loss: 14093.6465\n",
      "Epoch 5/50, Loss: 16939.2910\n",
      "Epoch 6/50, Loss: 9070.6289\n",
      "Epoch 7/50, Loss: 7212.6260\n",
      "Epoch 8/50, Loss: 7308.2671\n",
      "Epoch 9/50, Loss: 6196.1685\n",
      "Epoch 10/50, Loss: 4910.9473\n",
      "Epoch 11/50, Loss: 5052.1987\n",
      "Epoch 12/50, Loss: 4611.6992\n",
      "Epoch 13/50, Loss: 3630.7588\n",
      "Epoch 14/50, Loss: 3402.2129\n",
      "Epoch 15/50, Loss: 3060.9097\n",
      "Epoch 16/50, Loss: 2540.0642\n",
      "Epoch 17/50, Loss: 2406.5054\n",
      "Epoch 18/50, Loss: 2061.3201\n",
      "Epoch 19/50, Loss: 1802.6008\n",
      "Epoch 20/50, Loss: 1610.7126\n",
      "Epoch 21/50, Loss: 1502.1685\n",
      "Epoch 22/50, Loss: 1211.6895\n",
      "Epoch 23/50, Loss: 1113.4557\n",
      "Epoch 24/50, Loss: 1012.1248\n",
      "Epoch 25/50, Loss: 850.7432\n",
      "Epoch 26/50, Loss: 844.5101\n",
      "Epoch 27/50, Loss: 703.1438\n",
      "Epoch 28/50, Loss: 624.6495\n",
      "Epoch 29/50, Loss: 586.9553\n",
      "Epoch 30/50, Loss: 538.3320\n",
      "Epoch 31/50, Loss: 578.0394\n",
      "Epoch 32/50, Loss: 547.5119\n",
      "Epoch 33/50, Loss: 471.8807\n",
      "Epoch 34/50, Loss: 405.0645\n",
      "Epoch 35/50, Loss: 401.9098\n",
      "Epoch 36/50, Loss: 365.0219\n",
      "Epoch 37/50, Loss: 371.9532\n",
      "Epoch 38/50, Loss: 361.0978\n",
      "Epoch 39/50, Loss: 350.1032\n",
      "Epoch 40/50, Loss: 331.0553\n",
      "Epoch 41/50, Loss: 328.3482\n",
      "Epoch 42/50, Loss: 308.6782\n",
      "Epoch 43/50, Loss: 308.1163\n",
      "Epoch 44/50, Loss: 265.6953\n",
      "Epoch 45/50, Loss: 266.4515\n",
      "Epoch 46/50, Loss: 250.1418\n",
      "Epoch 47/50, Loss: 257.2159\n",
      "Epoch 48/50, Loss: 271.8886\n",
      "Epoch 49/50, Loss: 253.1446\n",
      "Epoch 50/50, Loss: 224.6394\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "num_epochs = 50\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    loss = model(X, y, mask=mask)   # forward pass\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "098a75d8-c49d-468b-8d4a-a836a6e4739b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T06:13:15.846365Z",
     "iopub.status.busy": "2025-10-07T06:13:15.845695Z",
     "iopub.status.idle": "2025-10-07T06:13:15.850033Z",
     "shell.execute_reply": "2025-10-07T06:13:15.849230Z",
     "shell.execute_reply.started": "2025-10-07T06:13:15.846340Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "idx2label = {idx: label for label, idx in label2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39ec2ae2-f66e-4ef4-bbd2-ec5c80e34404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T06:13:17.079472Z",
     "iopub.status.busy": "2025-10-07T06:13:17.079228Z",
     "iopub.status.idle": "2025-10-07T06:13:17.745403Z",
     "shell.execute_reply": "2025-10-07T06:13:17.744770Z",
     "shell.execute_reply.started": "2025-10-07T06:13:17.079455Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions type: <class 'list'>\n",
      "first pred length: 3 expected length: 3\n",
      "f1: 0.9742639890816923 accuracy: 0.9742639890816923\n"
     ]
    }
   ],
   "source": [
    "# Eval mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X, mask=mask)   # list[list[int]]\n",
    "\n",
    "print(\"predictions type:\", type(predictions))\n",
    "print(\"first pred length:\", len(predictions[0]), \"expected length:\", int(mask[0].sum().item()))\n",
    "\n",
    "# Robust flattening using mask sums\n",
    "mask_bool = (X != token2idx[\"<PAD>\"])  \n",
    "y_true_flat = y[mask_bool].cpu().numpy()\n",
    "\n",
    "y_pred_flat = []\n",
    "for seq_pred, seq_mask in zip(predictions, mask_bool):\n",
    "    seq_len = int(seq_mask.sum().item())\n",
    "    y_pred_flat.extend(seq_pred[:seq_len])\n",
    "\n",
    "y_pred_flat = np.array(y_pred_flat)\n",
    "\n",
    "# Exclude PAD labels if present\n",
    "pad_id = label2idx.get(\"<PAD>\", None)\n",
    "if pad_id is not None:\n",
    "    valid = (y_true_flat != pad_id)\n",
    "    y_true_final = y_true_flat[valid]\n",
    "    y_pred_final = y_pred_flat[valid]\n",
    "else:\n",
    "    y_true_final = y_true_flat\n",
    "    y_pred_final = y_pred_flat\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "f1 = f1_score(y_true_final, y_pred_final, average='micro')\n",
    "acc = accuracy_score(y_true_final, y_pred_final)\n",
    "print(\"f1:\", f1, \"accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80e981f-435a-4b01-9d05-ccf6dc98ab08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T06:13:22.458210Z",
     "iopub.status.busy": "2025-10-07T06:13:22.457400Z",
     "iopub.status.idle": "2025-10-07T06:13:22.573840Z",
     "shell.execute_reply": "2025-10-07T06:13:22.573101Z",
     "shell.execute_reply.started": "2025-10-07T06:13:22.458184Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE: ['O', 'B-DEP', 'I-DEP']\n",
      "PRED: ['O', 'B-DEP', 'I-DEP']\n",
      "\n",
      "TRUE: ['O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC']\n",
      "PRED: ['O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC', 'I-LOC']\n",
      "\n",
      "TRUE: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "PRED: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx2label = {v:k for k,v in label2idx.items()}\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(X, mask=mask)\n",
    "\n",
    "for i in range(min(3, X.size(0))):\n",
    "    seq_len = int(mask[i].sum().item())\n",
    "    true_seq = y[i, :seq_len].cpu().tolist()\n",
    "    pred_seq = preds[i][:seq_len]\n",
    "    print(\"TRUE:\", [idx2label[t] for t in true_seq])\n",
    "    print(\"PRED:\", [idx2label[p] for p in pred_seq])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c994015e-7249-4072-ac50-a13e0f865cf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T06:13:28.246445Z",
     "iopub.status.busy": "2025-10-07T06:13:28.245667Z",
     "iopub.status.idle": "2025-10-07T06:13:28.253566Z",
     "shell.execute_reply": "2025-10-07T06:13:28.252973Z",
     "shell.execute_reply.started": "2025-10-07T06:13:28.246421Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['chính', 'ph', 'ủ', '-', '-', '-', '-', '-', '-', '-', '-', 'cộng', 'hòa', 'xã', 'hội', 'chủ', 'nghĩa', 'việt', 'nam', 'độc', 'lập', '-', 'tự', 'do', '-', 'hạnh', 'phúc', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', 'số', ':', '83', '/', 'nq', '-', 'cp', 'hà', 'n', 'ội', ',', 'ngày', '08', 'tháng', '6', 'năm', '2024', 'nghị', 'quyết', 'về', 'dự', 'án', 'ngh', 'ị', 'quy', 'ết', 'của', 'qu', 'ốc', 'hội', 'về', 'giảm', 'thu', 'ế', 'giá', 'tr', 'ị', 'gia', 'tăng', 'chính', 'ph', 'ủ', 'căn', 'c', 'ứ', 'luật', 'tổ', 'chức', 'chính', 'ph', 'ủ', 'ngày', '19', 'tháng', '6', 'năm', '2015', ';', 'lu', 'ật', 'sửa', 'đổi', ',', 'bổ', 'sung', 'm', 'ột', 'số', 'điều', 'của', 'luật', 'tổ', 'chức', 'chính', 'ph', 'ủ', 'và', 'lu', 'ật', 'tổ', 'chức', 'chính', 'quy', 'ền', 'địa', 'phương', 'ngày', '22', 'tháng', '11', 'năm', '2019', ';', 'căn', 'c', 'ứ', 'luật', 'ban', 'hành', 'văn', 'b', 'ản', 'quy', 'ph', 'ạm', 'pháp', 'lu', 'ật', 'ngày', '22', 'tháng', '6', 'năm', '2015', ';', 'lu', 'ật', 'sửa', 'đổi', ',', 'bổ', 'sung', 'm', 'ột', 'số', 'điều', 'của', 'luật', 'ban', 'hành', 'văn', 'b', 'ản', 'quy', 'ph', 'ạm', 'pháp', 'lu', 'ật', 'ngày', '18', 'tháng', '6', 'năm', '2020', ';', 'căn', 'c', 'ứ', 'nghị', 'định', 'số', '39', '/', '2022', '/', 'nđ', '-', 'cp', 'ngày', '18', 'tháng', '6', 'năm', '2022', 'c', 'ủa', 'chính', 'ph', 'ủ', 'ban', 'hành', 'quy', 'ch', 'ế', 'làm', 'vi', 'ệc', 'của', 'chính', 'ph', 'ủ', ';', 'xét', 'đ', 'ề', 'nghị', 'của', 'bộ', 'trưởng', 'bộ', 'tài', 'chính', 't', 'ại', 'tờ', 'trình', 's', 'ố', '127', '/', 'ttr', '-', 'btc', 'ngày', '06', 'tháng', '6', 'năm', '2024', ';', 'trên', 'cơ', 's', 'ở', 'kết', 'quả', 'biểu', 'quy', 'ết', 'của', 'các', 'thành', 'viên', 'chính', 'ph', 'ủ', ',', 'quyết', 'nghị', ':', 'điều', '1', '.']\n",
      "Tensor shape: torch.Size([1, 276])\n",
      "Mask shape: torch.Size([1, 276])\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sentence = '''\n",
    "CHÍNH PH Ủ \n",
    "--------  CỘNG HÒA XÃ HỘI CHỦ NGHĨA VIỆT NAM  \n",
    "Độc lập - Tự do - Hạnh phúc  \n",
    "---------------  \n",
    "Số: 83/NQ -CP Hà N ội, ngày  08 tháng  6 năm 2024  \n",
    "  \n",
    "NGHỊ QUYẾT \n",
    "VỀ DỰ ÁN NGH Ị QUY ẾT CỦA QU ỐC HỘI VỀ GIẢM THU Ế GIÁ TR Ị GIA TĂNG  \n",
    "CHÍNH PH Ủ \n",
    "Căn c ứ Luật Tổ chức Chính ph ủ ngày 19 tháng 6 năm 2015; Lu ật sửa đổi, bổ sung m ột \n",
    "số điều của Luật Tổ chức Chính ph ủ và Lu ật Tổ chức Chính quy ền địa phương ngày 22 \n",
    "tháng 11 năm 2019;  \n",
    "Căn c ứ Luật ban hành văn b ản quy ph ạm pháp lu ật ngày 22 tháng 6 năm 2015; Lu ật \n",
    "sửa đổi, bổ sung m ột số điều của Luật ban hành văn b ản quy ph ạm pháp lu ật ngày 18 \n",
    "tháng 6 năm 2020;  \n",
    "Căn c ứ Nghị định số 39/2022/NĐ -CP ngày 18 tháng 6 năm 2022 c ủa Chính ph ủ ban \n",
    "hành Quy ch ế làm vi ệc của Chính ph ủ; \n",
    "Xét đ ề nghị của Bộ trưởng Bộ Tài chính t ại Tờ trình s ố 127/TTr -BTC ngày 06 tháng 6 \n",
    "năm 2024;  \n",
    "Trên cơ s ở kết quả biểu quy ết của các Thành viên Chính ph ủ, \n",
    "QUYẾT NGHỊ: \n",
    "Điều 1.\n",
    "\n",
    "'''\n",
    "\n",
    "lower_sentence = sentence.lower().strip()\n",
    "\n",
    "# Tokenize the data to match the Label-Studio style of splitting tokens\n",
    "def tokenize_like_conll(text):\n",
    "    \"\"\"\n",
    "    Split tokens like Label Studio:\n",
    "    - Separate punctuation (/,:; etc.)\n",
    "    - Split numbers, letters, symbols\n",
    "    \"\"\"\n",
    "    return re.findall(r\"\\w+|[^\\w\\s]\", text, re.UNICODE)\n",
    "\n",
    "tokens = tokenize_like_conll(lower_sentence)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Convert tokens to indices \n",
    "X_test = [token2idx.get(tok, token2idx[\"<UNK>\"]) for tok in tokens]\n",
    "\n",
    "# Convert to tensor\n",
    "X_test_tensor = torch.tensor([X_test], dtype=torch.long).to(device)  # shape: (1, seq_len)\n",
    "\n",
    "# Create attention mask\n",
    "mask_test = (X_test_tensor != token2idx[\"<PAD>\"]).to(torch.bool)\n",
    "\n",
    "print(\"Tensor shape:\", X_test_tensor.shape)\n",
    "print(\"Mask shape:\", mask_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7feb635f-3503-43b3-9b07-560363e4b876",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T06:13:30.748896Z",
     "iopub.status.busy": "2025-10-07T06:13:30.748180Z",
     "iopub.status.idle": "2025-10-07T06:13:30.784480Z",
     "shell.execute_reply": "2025-10-07T06:13:30.783976Z",
     "shell.execute_reply.started": "2025-10-07T06:13:30.748873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_test_tensor = X_test_tensor.to(device)\n",
    "mask_test = mask_test.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor, mask=mask_test)\n",
    "\n",
    "pred_labels = [idx2label[idx] for idx in predictions[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42661e3d-8c75-410a-ba3a-bb4041408ff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T06:13:31.759008Z",
     "iopub.status.busy": "2025-10-07T06:13:31.758761Z",
     "iopub.status.idle": "2025-10-07T06:13:31.794217Z",
     "shell.execute_reply": "2025-10-07T06:13:31.793493Z",
     "shell.execute_reply.started": "2025-10-07T06:13:31.758992Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor, mask=mask_test)\n",
    "\n",
    "pred_labels = [idx2label[idx] for idx in predictions[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9884909c-0839-46af-a6be-4c84861638b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T06:13:32.979166Z",
     "iopub.status.busy": "2025-10-07T06:13:32.978630Z",
     "iopub.status.idle": "2025-10-07T06:13:32.984259Z",
     "shell.execute_reply": "2025-10-07T06:13:32.983663Z",
     "shell.execute_reply.started": "2025-10-07T06:13:32.979147Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chính: B-DEP\n",
      "ph: I-DEP\n",
      "ủ: I-DEP\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "cộng: B-LOC\n",
      "hòa: I-LOC\n",
      "xã: I-LOC\n",
      "hội: I-LOC\n",
      "chủ: I-LOC\n",
      "nghĩa: I-LOC\n",
      "việt: I-LOC\n",
      "nam: I-LOC\n",
      "độc: O\n",
      "lập: O\n",
      "-: O\n",
      "tự: O\n",
      "do: O\n",
      "-: O\n",
      "hạnh: O\n",
      "phúc: O\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "-: O\n",
      "số: O\n",
      ":: O\n",
      "83: B-DOCID\n",
      "/: I-DOCID\n",
      "nq: I-DOCID\n",
      "-: O\n",
      "cp: O\n",
      "hà: B-LOC\n",
      "n: I-LOC\n",
      "ội: I-LOC\n",
      ",: O\n",
      "ngày: B-DAT\n",
      "08: I-DAT\n",
      "tháng: I-DAT\n",
      "6: I-DAT\n",
      "năm: I-DAT\n",
      "2024: I-DAT\n",
      "nghị: O\n",
      "quyết: B-TIT\n",
      "về: B-TIT\n",
      "dự: I-TIT\n",
      "án: I-TIT\n",
      "ngh: I-TIT\n",
      "ị: I-TIT\n",
      "quy: I-TIT\n",
      "ết: I-TIT\n",
      "của: I-TIT\n",
      "qu: I-TIT\n",
      "ốc: I-TIT\n",
      "hội: I-TIT\n",
      "về: I-TIT\n",
      "giảm: I-TIT\n",
      "thu: I-TIT\n",
      "ế: I-TIT\n",
      "giá: I-TIT\n",
      "tr: I-TIT\n",
      "ị: I-TIT\n",
      "gia: I-TIT\n",
      "tăng: I-TIT\n",
      "chính: B-DEP\n",
      "ph: I-DEP\n",
      "ủ: I-DEP\n",
      "căn: O\n",
      "c: O\n",
      "ứ: O\n",
      "luật: B-TIT\n",
      "tổ: I-TIT\n",
      "chức: I-TIT\n",
      "chính: I-TIT\n",
      "ph: I-TIT\n",
      "ủ: I-TIT\n",
      "ngày: B-DAT\n",
      "19: I-DAT\n",
      "tháng: I-DAT\n",
      "6: I-DAT\n",
      "năm: I-DAT\n",
      "2015: I-DAT\n",
      ";: O\n",
      "lu: B-TIT\n",
      "ật: I-TIT\n",
      "sửa: I-TIT\n",
      "đổi: I-TIT\n",
      ",: I-TIT\n",
      "bổ: I-TIT\n",
      "sung: I-TIT\n",
      "m: I-TIT\n",
      "ột: I-TIT\n",
      "số: I-TIT\n",
      "điều: I-TIT\n",
      "của: O\n",
      "luật: B-TIT\n",
      "tổ: I-TIT\n",
      "chức: I-TIT\n",
      "chính: I-TIT\n",
      "ph: I-TIT\n",
      "ủ: I-TIT\n",
      "và: O\n",
      "lu: B-TIT\n",
      "ật: I-TIT\n",
      "tổ: I-TIT\n",
      "chức: I-TIT\n",
      "chính: I-TIT\n",
      "quy: I-TIT\n",
      "ền: I-TIT\n",
      "địa: I-TIT\n",
      "phương: I-TIT\n",
      "ngày: B-DAT\n",
      "22: I-DAT\n",
      "tháng: I-DAT\n",
      "11: I-DAT\n",
      "năm: I-DAT\n",
      "2019: I-DAT\n",
      ";: O\n",
      "căn: O\n",
      "c: O\n",
      "ứ: O\n",
      "luật: B-TIT\n",
      "ban: I-TIT\n",
      "hành: I-TIT\n",
      "văn: I-TIT\n",
      "b: I-TIT\n",
      "ản: I-TIT\n",
      "quy: I-TIT\n",
      "ph: I-TIT\n",
      "ạm: I-TIT\n",
      "pháp: I-TIT\n",
      "lu: I-TIT\n",
      "ật: I-TIT\n",
      "ngày: B-DAT\n",
      "22: I-DAT\n",
      "tháng: I-DAT\n",
      "6: I-DAT\n",
      "năm: I-DAT\n",
      "2015: I-DAT\n",
      ";: O\n",
      "lu: B-TIT\n",
      "ật: I-TIT\n",
      "sửa: I-TIT\n",
      "đổi: I-TIT\n",
      ",: I-TIT\n",
      "bổ: I-TIT\n",
      "sung: I-TIT\n",
      "m: I-TIT\n",
      "ột: I-TIT\n",
      "số: I-TIT\n",
      "điều: I-TIT\n",
      "của: O\n",
      "luật: B-TIT\n",
      "ban: I-TIT\n",
      "hành: I-TIT\n",
      "văn: I-TIT\n",
      "b: I-TIT\n",
      "ản: I-TIT\n",
      "quy: I-TIT\n",
      "ph: I-TIT\n",
      "ạm: I-TIT\n",
      "pháp: I-TIT\n",
      "lu: I-TIT\n",
      "ật: I-TIT\n",
      "ngày: B-DAT\n",
      "18: I-DAT\n",
      "tháng: I-DAT\n",
      "6: I-DAT\n",
      "năm: I-DAT\n",
      "2020: I-DAT\n",
      ";: O\n",
      "căn: O\n",
      "c: O\n",
      "ứ: O\n",
      "nghị: B-TIT\n",
      "định: I-TIT\n",
      "số: O\n",
      "39: B-DOCID\n",
      "/: I-DOCID\n",
      "2022: I-DOCID\n",
      "/: I-DOCID\n",
      "nđ: I-DOCID\n",
      "-: I-DOCID\n",
      "cp: I-TIT\n",
      "ngày: B-DAT\n",
      "18: I-DAT\n",
      "tháng: I-DAT\n",
      "6: I-DAT\n",
      "năm: I-DAT\n",
      "2022: I-DAT\n",
      "c: O\n",
      "ủa: O\n",
      "chính: B-DEP\n",
      "ph: I-DEP\n",
      "ủ: I-DEP\n",
      "ban: O\n",
      "hành: O\n",
      "quy: B-TIT\n",
      "ch: I-TIT\n",
      "ế: I-TIT\n",
      "làm: I-TIT\n",
      "vi: I-TIT\n",
      "ệc: I-TIT\n",
      "của: O\n",
      "chính: B-DEP\n",
      "ph: I-DEP\n",
      "ủ: I-DEP\n",
      ";: O\n",
      "xét: O\n",
      "đ: O\n",
      "ề: O\n",
      "nghị: O\n",
      "của: O\n",
      "bộ: B-PER\n",
      "trưởng: I-PER\n",
      "bộ: B-DEP\n",
      "tài: I-DEP\n",
      "chính: I-DEP\n",
      "t: O\n",
      "ại: O\n",
      "tờ: B-TIT\n",
      "trình: I-TIT\n",
      "s: O\n",
      "ố: O\n",
      "127: B-DOCID\n",
      "/: I-DOCID\n",
      "ttr: I-DOCID\n",
      "-: O\n",
      "btc: O\n",
      "ngày: B-DAT\n",
      "06: I-DAT\n",
      "tháng: I-DAT\n",
      "6: I-DAT\n",
      "năm: I-DAT\n",
      "2024: I-DAT\n",
      ";: O\n",
      "trên: O\n",
      "cơ: O\n",
      "s: O\n",
      "ở: O\n",
      "kết: O\n",
      "quả: O\n",
      "biểu: O\n",
      "quy: O\n",
      "ết: O\n",
      "của: O\n",
      "các: O\n",
      "thành: B-PER\n",
      "viên: I-PER\n",
      "chính: B-DEP\n",
      "ph: I-DEP\n",
      "ủ: I-DEP\n",
      ",: O\n",
      "quyết: O\n",
      "nghị: B-TIT\n",
      ":: I-TIT\n",
      "điều: I-TIT\n",
      "1: I-TIT\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for token, label in zip(tokens, pred_labels):\n",
    "    print(f\"{token}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e504fee-25ed-4d43-9202-add3c8c86e45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T06:18:28.790351Z",
     "iopub.status.busy": "2025-10-07T06:18:28.789771Z",
     "iopub.status.idle": "2025-10-07T06:18:28.806588Z",
     "shell.execute_reply": "2025-10-07T06:18:28.806013Z",
     "shell.execute_reply.started": "2025-10-07T06:18:28.790328Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and dictionaries saved successfully!\n"
     ]
    }
   ],
   "source": [
    "### Save model\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Example: paths to save\n",
    "MODEL_PATH = \"model_bilstm_crf.pt\"\n",
    "TOKEN_PATH = \"token2idx.json\"\n",
    "LABEL_PATH = \"label2idx.json\"\n",
    "\n",
    "# --- Save model weights ---\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "\n",
    "# --- Save dictionaries ---\n",
    "with open(TOKEN_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(token2idx, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(LABEL_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(label2idx, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ Model and dictionaries saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe05dc56-f063-4773-9d79-abdceed95414",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8420617,
     "sourceId": 13286703,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
